# LLM Orchestrator Configuration

# Redis Settings (MUST match gateway and other services)
REDIS_HOST=localhost
REDIS_PORT=6379
# REDIS_DB=0
# REDIS_PASSWORD=

# Channels (Defaults are in llm_orchestrator/config.py. Uncomment to override, ensure consistency.)
# TRANSCRIPT_CHANNEL="transcript_channel"         # Channel to subscribe to for final transcripts from VAD/STT
# LLM_TOKEN_CHANNEL="llm_token_channel"           # Channel to publish LLM stream tokens to (for Gateway)
# LLM_TOOL_CALL_CHANNEL="llm_tool_call_channel"   # Channel to publish LLM tool calls/status to (for Gateway)
# TTS_REQUEST_CHANNEL="tts_request_channel"       # Channel to publish TTS synthesis requests to
# BARGE_IN_CHANNEL="barge_in_notifications"     # Channel to subscribe to for barge-in events from VAD/STT
# TTS_CONTROL_CHANNEL="tts_control_channel"       # Channel to send control commands (e.g., stop_tts) to TTS Service

# Conversation Context Storage (Defaults are in config.py)
# CONVERSATION_HISTORY_PREFIX="conversation_history:"
# CONVERSATION_CONFIG_PREFIX="conversation_config:" # Used to read config set by Gateway API
# CONVERSATION_DATA_TTL_SECONDS=86400 # 24 hours for history/config TTL in Redis
# MAX_CONVERSATION_HISTORY=10 # Max user/assistant turn pairs in history sent to LLM

# LLM Provider Settings (FR-05)
LLM_PROVIDER="openai"  # Example: "openai", "anthropic", "ollama", etc.
LLM_MODEL_NAME="gpt-3.5-turbo" # Specify the model to use
LLM_API_KEY="sk-YOUR_OPENAI_API_KEY_HERE" # IMPORTANT: Replace with your actual API key for the provider
# LLM_BASE_URL="https://api.openai.com/v1" # Optional: if using a proxy or different endpoint for OpenAI-compatible APIs
# LLM_MAX_TOKENS=1024
# LLM_TEMPERATURE=0.7

# Default TTS Settings (used if not overridden by conversation-specific config)
# DEFAULT_TTS_VOICE_ID="fr_FR-siwis-medium" # Example Piper voice ID (model file name without .onnx)

# Logging Level (Optional - default is typically INFO or DEBUG in logging_config.py)
LOG_LEVEL="INFO"